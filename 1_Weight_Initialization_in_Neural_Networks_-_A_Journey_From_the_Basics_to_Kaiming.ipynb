{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c990ed",
   "metadata": {},
   "source": [
    "# Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe94877",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590d119",
   "metadata": {},
   "source": [
    "The objective of this notebook is to follow [this](https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79) article as it demonstrates weight initialization in neural networks, the issues associated with it and solutions to said issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a11fc5",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a3300",
   "metadata": {},
   "source": [
    "* Neural networks are made of a layered architecture with each layer containing a set of weights, biases and an activation function\n",
    "\n",
    "* Input to a layer is first multiplied with the weights, then biases are added to the product and finally it is passed through the activation function\n",
    "\n",
    "* At the start of the training phase for an NN, weights and biases need to be initialized to any value, from where the training then corrects these values to reduce prediction error\n",
    "\n",
    "    * Traditionally, weights are initialized by sampling from a standard normal distribution, while the biases are set to 1\n",
    "\n",
    "    * However, this initialization can lead to exploding gradients (output from the layer becomes infinite or nan) or vanishing gradients (output becomes 0), which can prevent the training from converging to an optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e79feb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab05198",
   "metadata": {},
   "source": [
    "Vector of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3811d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c13f9b",
   "metadata": {},
   "source": [
    "Simulation of 100 layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211946c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(nan), tensor(nan))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    weight = torch.randn(512, 512)\n",
    "    x = weight @ x\n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcb6b6",
   "metadata": {},
   "source": [
    "During the forward pass through 100 layers, network weights got close to infinity or nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16177a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    weight = torch.randn(512, 512)\n",
    "    x = weight @ x\n",
    "    if torch.isnan(x.std()):\n",
    "        break\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62aeb3",
   "metadata": {},
   "source": [
    "Weights exploded within 28 layers of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41558bab",
   "metadata": {},
   "source": [
    "For vanishing gradients, we are sampling from normal distribution with mean 0 but scaling to get standard deviation 0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15424a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    weight = torch.randn(512, 512) * 0.01\n",
    "    x = weight @ x\n",
    "    \n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf70e77",
   "metadata": {},
   "source": [
    "The matrix product of an input $x$ and weight matrix $weight$ initialized from a standard normal distribution will have standard deviation close to square root of number of input connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c8040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var = 0.0, 0.0\n",
    "\n",
    "for i in range(1000):\n",
    "    x = torch.randn(512)\n",
    "    weight = torch.randn(512, 512)\n",
    "    y = weight @ x\n",
    "    mean += y.mean().item()\n",
    "    var += y.pow(2).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98f3c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002180554822087288, 22.629027893656087)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean / 1000, math.sqrt(var / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a863bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.627416997969522"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2bf42",
   "metadata": {},
   "source": [
    "This is because matrix multiplication in this example is a sum of 512 products of elements of $x$ and $weight$. Since both $x$ and $weight$ are initialized from a standard normal distribution, the 512 products would have a mean 0 and standard deviation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "370a0be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005823576229463287, 0.9878580677864147)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, var = 0.0, 0.0\n",
    "\n",
    "for i in range(10000):\n",
    "    x = torch.randn(1)\n",
    "    a = torch.randn(1)\n",
    "    y = a * x\n",
    "    mean += y.item()\n",
    "    var += y.pow(2).item()\n",
    "    \n",
    "mean / 10000, math.sqrt(var / 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7442718",
   "metadata": {},
   "source": [
    "In our example, we would like to have each layer's outputs to have standard deviation of 1, which would prevent exploding gradients. This will be done by scaling with $\\frac{1}{\\sqrt{512}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32508da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0011965707547497003, 0.9980551573634148)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, var = 0.0, 0.0\n",
    "\n",
    "for i in range(1000):\n",
    "    x = torch.randn(512)\n",
    "    a = torch.randn(512, 512) * math.sqrt(1. / 512)\n",
    "    y = a @ x\n",
    "    mean += y.mean().item()\n",
    "    var += y.pow(2).mean().item()\n",
    "    \n",
    "mean / 1000, var / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84071a5",
   "metadata": {},
   "source": [
    "Doing this for the 100 layer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd8d33a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.5199e-05), tensor(0.0444))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    weight = torch.randn(512, 512) * math.sqrt(1. / 512)\n",
    "    x = weight @ a\n",
    "    \n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27158b56",
   "metadata": {},
   "source": [
    "Using the traditional symmetric activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b04563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c923bc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0021), tensor(0.0763))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    weight = torch.randn(512, 512) * math.sqrt(1. / 512)\n",
    "    x = tanh(weight @ x)\n",
    "    \n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962df8c3",
   "metadata": {},
   "source": [
    "### Xavier Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7aa18",
   "metadata": {},
   "source": [
    "* $$\\pm\\frac{\\sqrt{6}}{\\sqrt{n_{i} + n_{i + 1}}}$$\n",
    "\n",
    "    * $n_{i}$ is number of incoming network connections (fan-in) to the layer and $n_{i+1}$ are number of outgoing connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e42c42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier(m, h):\n",
    "    return torch.Tensor(m, h).uniform_(-1, 1) * math.sqrt(6./(m+h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d53592e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0008), tensor(0.0868))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    weight = xavier(512, 512)\n",
    "    x = tanh(weight @ x)\n",
    "    \n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f04ec3",
   "metadata": {},
   "source": [
    "Trying the same for ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83208f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2225de28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.016544756889344, 15.992926274173755)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, var = 0., 0.\n",
    "\n",
    "for i in range(1000):\n",
    "    x = torch.randn(512)\n",
    "    weight = torch.randn(512, 512)\n",
    "    y = relu(weight @ x)\n",
    "    \n",
    "    mean += y.mean().item()\n",
    "    var += y.pow(2).mean().item()\n",
    "    \n",
    "mean / 1000, math.sqrt(var / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b1d84ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(512) / math.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464a1eb",
   "metadata": {},
   "source": [
    "Scaling by this number would get individual ReLU layers to have standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed9f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5638078674376011, 0.9993184797611605)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, var = 0., 0.\n",
    "\n",
    "for i in range(1000):\n",
    "    x = torch.randn(512)\n",
    "    weight = torch.randn(512, 512) * math.sqrt(2 / 512)\n",
    "    y = relu(weight @ x)\n",
    "    \n",
    "    mean += y.mean().item()\n",
    "    var += y.pow(2).mean().item()\n",
    "    \n",
    "mean / 1000, math.sqrt(var / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d178d",
   "metadata": {},
   "source": [
    "### Kaiming Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a1620",
   "metadata": {},
   "source": [
    "* Create a tensor with the dimensions appropriate for a weight matrix at a given layer, and populate it with numbers randomly chosen from a standard normal distribution.\n",
    "\n",
    "* Multiply each randomly chosen number by √2/√n where n is the number of incoming connections coming into a given layer from the previous layer’s output (also known as the “fan-in”).\n",
    "\n",
    "* Bias tensors are initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "179cee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming(m, h):\n",
    "    return torch.randn(m, h) * math.sqrt(2. / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bb491cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5415), tensor(0.7596))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    weight = kaiming(512, 512)\n",
    "    x = relu(weight @ x)\n",
    "\n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6115cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.7588e-16), tensor(8.4180e-16))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    weight = xavier(512, 512)\n",
    "    x = relu(weight @ x)\n",
    "\n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee918a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
